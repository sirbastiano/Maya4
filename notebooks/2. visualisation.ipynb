{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e3cc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from maya4 import list_base_files_in_repo, list_repos_by_author\n",
    "import pandas as pd\n",
    "\n",
    "# ============================================================================\n",
    "# üó∫Ô∏è FEATURE 1: DATASET EXPLORATION - Browse Available Products\n",
    "# ============================================================================\n",
    "print('='*80)\n",
    "print('üó∫Ô∏è Exploring Available SAR Products on HuggingFace')\n",
    "print('='*80 + '\\n')\n",
    "\n",
    "def extract_product_info(filename: str) -> tuple:\n",
    "    \"\"\"\n",
    "    Extract polarization and product name from SAR filename.\n",
    "    \n",
    "    Args:\n",
    "        filename: SAR product filename (e.g., \"s1a-s1-raw-s-hh-20230508t121142-....zarr\")\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (product_name_without_polarization, polarization)\n",
    "        \n",
    "    Example:\n",
    "        Input:  \"s1a-s6-raw-s-vh-20231004t082954-20231004t083025-050613-0618e5.zarr\"\n",
    "        Output: (\"s1a-s6-raw-s-20231004t082954-20231004t083025-050613-0618e5\", \"VH\")\n",
    "    \"\"\"\n",
    "    if not filename.endswith('.zarr'):\n",
    "        return None, None\n",
    "    \n",
    "    # Remove .zarr extension\n",
    "    name_without_ext = filename.replace('.zarr', '')\n",
    "    \n",
    "    # Split by hyphen\n",
    "    parts = name_without_ext.split('-')\n",
    "    \n",
    "    if len(parts) >= 5:\n",
    "        # Extract polarization (5th token, index 4)\n",
    "        polarization = parts[4].upper()  # VH, VV, HH, HV\n",
    "        \n",
    "        # Create product name by removing the polarization part\n",
    "        product_parts = parts[:4] + parts[5:]\n",
    "        product_name = '-'.join(product_parts)\n",
    "        \n",
    "        return product_name, polarization\n",
    "    else:\n",
    "        # Fallback if filename doesn't match expected pattern\n",
    "        return name_without_ext, \"UNKNOWN\"\n",
    "\n",
    "\n",
    "# List all repositories from Maya4 organization on HuggingFace\n",
    "try:\n",
    "    projects = list_repos_by_author(author=\"Maya4\")\n",
    "    print(f'‚úì Found {len(projects)} repositories in Maya4 organization:\\n')\n",
    "    \n",
    "    # Create a comprehensive catalog of all available products\n",
    "    product_catalog = pd.DataFrame({\n",
    "        \"Product Name\": [],\n",
    "        \"File Name\": [],\n",
    "        \"Polarization\": [],\n",
    "        \"Repository\": []\n",
    "    })\n",
    "    \n",
    "    # Iterate through each repository (PT1, PT2, etc.)\n",
    "    for i, project in enumerate(projects, 1):\n",
    "        print(f'   {i}. {project}', end=' ')\n",
    "        \n",
    "        # List all SAR product files in this repository\n",
    "        remote_files = list_base_files_in_repo(repo_id=f\"{project}\")\n",
    "        print(f'({len(remote_files)} products)')\n",
    "        \n",
    "        # Extract metadata from each filename\n",
    "        for file in remote_files:\n",
    "            prod_name, polarization = extract_product_info(file)\n",
    "            \n",
    "            if prod_name is not None and polarization is not None:\n",
    "                # Add to catalog\n",
    "                product_catalog = pd.concat([\n",
    "                    product_catalog,\n",
    "                    pd.DataFrame({\n",
    "                        \"Product Name\": [prod_name],\n",
    "                        \"File Name\": [file],\n",
    "                        \"Polarization\": [polarization],\n",
    "                        \"Repository\": [project]\n",
    "                    })\n",
    "                ], ignore_index=True)\n",
    "    \n",
    "    print(f'\\n‚úì Total products in catalog: {len(product_catalog)}')\n",
    "    \n",
    "    # Display summary statistics\n",
    "    print(f'\\nüìä Catalog Statistics:')\n",
    "    print(f'   ‚Ä¢ Polarizations: {product_catalog[\"Polarization\"].unique()}')\n",
    "    print(f'   ‚Ä¢ Products per repository:')\n",
    "    for repo in product_catalog[\"Repository\"].unique():\n",
    "        count = len(product_catalog[product_catalog[\"Repository\"] == repo])\n",
    "        print(f'     - {repo}: {count} products')\n",
    "    \n",
    "    # Show first few entries\n",
    "    print(f'\\nüìã Sample entries from catalog:')\n",
    "    print(product_catalog.head(10).to_string(index=False))\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f'‚ö†Ô∏è Could not fetch repository list: {e}')\n",
    "    print('   (This requires internet connection and HuggingFace access)')\n",
    "\n",
    "# ============================================================================\n",
    "# üé® FEATURE 2: SAMPLE VISUALIZATION\n",
    "# ============================================================================\n",
    "print('\\n' + '='*80)\n",
    "print('üé® Sample Visualization (if data available)')\n",
    "print('='*80 + '\\n')\n",
    "\n",
    "# Create a simple loader for visualization\n",
    "try:\n",
    "    viz_loader = get_sar_dataloader(\n",
    "        data_dir=DATA_DIR,\n",
    "        level_from=\"rcmc\",\n",
    "        level_to=\"az\",\n",
    "        batch_size=1,\n",
    "        num_workers=0,\n",
    "        patch_mode=\"rectangular\",\n",
    "        patch_size=(5000, 5000),  # Large patch for visualization\n",
    "        buffer=(0, 0),\n",
    "        stride=(1000, 1000),\n",
    "        shuffle_files=False,\n",
    "        patch_order=\"row\",\n",
    "        complex_valued=True,\n",
    "        save_samples=False,\n",
    "        backend=\"zarr\",\n",
    "        verbose=False,\n",
    "        samples_per_prod=1,\n",
    "        cache_size=10,\n",
    "        online=True,\n",
    "        max_products=1,\n",
    "        positional_encoding=False\n",
    "    )\n",
    "    \n",
    "    # The dataset has a built-in visualization method\n",
    "    # Usage: dataset.visualize_item([file_path, y_coord, x_coord], vminmax=(min, max))\n",
    "    print('‚úì Visualization loader created')\n",
    "    print('  Use: loader.dataset.visualize_item([file_path, y, x], vminmax=(min, max))')\n",
    "    print('  Example: Shows input and target side-by-side with amplitude/phase')\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f'‚ö†Ô∏è Visualization setup failed: {e}')\n",
    "\n",
    "# ============================================================================\n",
    "# üîç FEATURE 3: DIFFERENT PATCH SAMPLING STRATEGIES\n",
    "# ============================================================================\n",
    "print('\\n' + '='*80)\n",
    "print('üîç Patch Sampling Strategy Comparison')\n",
    "print('='*80 + '\\n')\n",
    "\n",
    "sampling_strategies = {\n",
    "    \"Row-wise (Horizontal Raster Scan)\": {\n",
    "        \"patch_order\": \"row\",\n",
    "        \"description\": \"Samples patches left‚Üíright, top‚Üíbottom like reading text\",\n",
    "        \"use_case\": \"Sequential horizontal feature learning, coherent spatial ordering\"\n",
    "    },\n",
    "    \"Column-wise (Vertical Raster Scan)\": {\n",
    "        \"patch_order\": \"col\",\n",
    "        \"description\": \"Samples patches top‚Üíbottom, left‚Üíright\",\n",
    "        \"use_case\": \"Range direction analysis, vertical feature extraction\"\n",
    "    },\n",
    "    \"Chunk-aligned (I/O Optimized)\": {\n",
    "        \"patch_order\": \"chunk\",\n",
    "        \"description\": \"Follows Zarr storage chunks for efficient disk/network access\",\n",
    "        \"use_case\": \"Maximum I/O performance, minimizes cache misses\"\n",
    "    },\n",
    "    \"Block Pattern Sampling\": {\n",
    "        \"patch_order\": \"row\",\n",
    "        \"block_pattern\": \"(32, -1)\",\n",
    "        \"description\": \"Divides image into blocks, samples within each block\",\n",
    "        \"use_case\": \"Stratified sampling, ensuring coverage across entire scene\"\n",
    "    }\n",
    "}\n",
    "\n",
    "for strategy_name, config in sampling_strategies.items():\n",
    "    print(f'üìç {strategy_name}')\n",
    "    print(f'   Configuration: {config.get(\"patch_order\", \"row\")}', end='')\n",
    "    if \"block_pattern\" in config:\n",
    "        print(f' with block_pattern={config[\"block_pattern\"]}')\n",
    "    else:\n",
    "        print()\n",
    "    print(f'   Description: {config[\"description\"]}')\n",
    "    print(f'   Use Case: {config[\"use_case\"]}\\n')\n",
    "\n",
    "# ============================================================================\n",
    "# üìä FEATURE 4: PROCESSING LEVEL COMBINATIONS\n",
    "# ============================================================================\n",
    "print('='*80)\n",
    "print('üìä Available Processing Level Combinations')\n",
    "print('='*80 + '\\n')\n",
    "\n",
    "processing_levels = {\n",
    "    \"raw ‚Üí rc\": {\n",
    "        \"task\": \"Range Compression\",\n",
    "        \"description\": \"Learn how radar echoes are compressed in range direction\",\n",
    "        \"complexity\": \"Low - 1D processing\"\n",
    "    },\n",
    "    \"rc ‚Üí rcmc\": {\n",
    "        \"task\": \"Range Cell Migration Correction\",\n",
    "        \"description\": \"Learn to correct for target motion during acquisition\",\n",
    "        \"complexity\": \"Medium - Geometric correction\"\n",
    "    },\n",
    "    \"rcmc ‚Üí az\": {\n",
    "        \"task\": \"Azimuth Compression (Focusing)\",\n",
    "        \"description\": \"Learn final focusing step to create SAR image\",\n",
    "        \"complexity\": \"High - 2D focusing\"\n",
    "    },\n",
    "    \"raw ‚Üí rcmc\": {\n",
    "        \"task\": \"Combined RC + RCMC\",\n",
    "        \"description\": \"Multi-stage processing in one step\",\n",
    "        \"complexity\": \"Medium-High - Combined operations\"\n",
    "    },\n",
    "    \"raw ‚Üí az\": {\n",
    "        \"task\": \"End-to-End SAR Processing\",\n",
    "        \"description\": \"Complete processing chain from echoes to image\",\n",
    "        \"complexity\": \"Very High - Full focusing pipeline\"\n",
    "    }\n",
    "}\n",
    "\n",
    "for level_pair, info in processing_levels.items():\n",
    "    print(f'üéØ {level_pair}')\n",
    "    print(f'   Task: {info[\"task\"]}')\n",
    "    print(f'   Description: {info[\"description\"]}')\n",
    "    print(f'   Complexity: {info[\"complexity\"]}\\n')\n",
    "\n",
    "# ============================================================================\n",
    "# üéì SUMMARY\n",
    "# ============================================================================\n",
    "print('='*80)\n",
    "print('üéì Key Takeaways')\n",
    "print('='*80)\n",
    "\n",
    "takeaways = [\n",
    "    \"Use filters to select specific years, polarizations, and modes\",\n",
    "    \"Choose processing levels (level_from ‚Üí level_to) based on your research goal\",\n",
    "    \"Optimize patch_order: 'chunk' for speed, 'row'/'col' for spatial coherence\",\n",
    "    \"Enable positional_encoding for models that need spatial awareness\",\n",
    "    \"Use concatenate_patches for sequence learning tasks\",\n",
    "    \"Set online=True to automatically download from HuggingFace\",\n",
    "    \"Start with max_products=1 for testing, then scale up\",\n",
    "    \"Use transforms for normalization - essential for neural network training\",\n",
    "    \"Complex_valued=True for native SAR representation, False for real/imag channels\",\n",
    "    \"Monitor verbose=True output during development for debugging\"\n",
    "]\n",
    "\n",
    "for i, takeaway in enumerate(takeaways, 1):\n",
    "    print(f'  {i:2d}. {takeaway}')\n",
    "\n",
    "print('\\n' + '='*80)\n",
    "print('‚úÖ Complete functionality demonstration finished!')\n",
    "print('='*80)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

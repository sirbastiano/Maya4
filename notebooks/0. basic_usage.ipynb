{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad13a6f3",
   "metadata": {},
   "source": [
    "## ðŸŽ¨ Visualization & Advanced Features\n",
    "\n",
    "Beyond basic data loading, Maya4 provides powerful visualization tools and advanced sampling strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15529d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "39c3eb65",
   "metadata": {},
   "source": [
    "## ðŸ“š Quick Reference Card\n",
    "\n",
    "Copy-paste ready configurations for common use cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba50ce7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "==============================================================================\n",
    "ðŸ“š QUICK REFERENCE: COPY-PASTE READY CONFIGURATIONS\n",
    "==============================================================================\n",
    "\n",
    "Common configurations for different research scenarios. Simply copy and modify!\n",
    "\"\"\"\n",
    "\n",
    "from maya4 import get_sar_dataloader, SARTransform, SampleFilter\n",
    "import functools\n",
    "from maya4 import minmax_normalize, RC_MIN, RC_MAX, GT_MIN, GT_MAX\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "DATA_DIR = os.path.abspath(os.path.join(os.getcwd(), '..', 'data'))\n",
    "\n",
    "# ============================================================================\n",
    "# ðŸŽ¯ CONFIG 1: FAST PROTOTYPING (Single Product, Quick Testing)\n",
    "# ============================================================================\n",
    "print('='*80)\n",
    "print('ðŸŽ¯ Configuration 1: Fast Prototyping')\n",
    "print('='*80 + '\\n')\n",
    "\n",
    "loader_prototype = get_sar_dataloader(\n",
    "    data_dir=DATA_DIR,\n",
    "    level_from=\"rcmc\",              # Input: Range Cell Migration Corrected\n",
    "    level_to=\"az\",                  # Output: Azimuth focused (focused image)\n",
    "    batch_size=4,                   # Small batch for quick iteration\n",
    "    num_workers=0,                  # Single process for easy debugging\n",
    "    patch_size=(1000, 1000),        # 1km Ã— 1km patches\n",
    "    stride=(1000, 1000),            # Non-overlapping patches\n",
    "    buffer=(500, 500),              # 500px boundary buffer\n",
    "    patch_order=\"chunk\",            # I/O efficient ordering\n",
    "    complex_valued=True,            # Native SAR complex representation\n",
    "    online=True,                    # Auto-download from HuggingFace\n",
    "    max_products=1,                 # Just 1 product for testing\n",
    "    samples_per_prod=50,            # 50 samples per product\n",
    "    cache_size=1,                   # Minimal cache\n",
    "    verbose=True,                   # Show debug information\n",
    "    use_balanced_sampling=False     # No balancing for single product\n",
    ")\n",
    "print('âœ“ Fast prototyping loader ready\\n')\n",
    "\n",
    "# ============================================================================\n",
    "# ðŸš€ CONFIG 2: FULL TRAINING (Production-Ready, Multi-Product)\n",
    "# ============================================================================\n",
    "print('='*80)\n",
    "print('ðŸš€ Configuration 2: Full Training Setup')\n",
    "print('='*80 + '\\n')\n",
    "\n",
    "# Define normalization transforms\n",
    "full_training_transforms = SARTransform(\n",
    "    transform_rcmc=functools.partial(minmax_normalize, array_min=RC_MIN, array_max=RC_MAX),\n",
    "    transform_az=functools.partial(minmax_normalize, array_min=GT_MIN, array_max=GT_MAX)\n",
    ")\n",
    "\n",
    "# Define product filters\n",
    "training_filters = SampleFilter(\n",
    "    years=[2023, 2024],             # Multi-year dataset\n",
    "    polarizations=[\"hh\", \"hv\"],     # Multiple polarizations\n",
    "    stripmap_modes=[1, 2, 3],       # Various swath modes\n",
    "    parts=None                       # All geographic regions\n",
    ")\n",
    "\n",
    "loader_training = get_sar_dataloader(\n",
    "    data_dir=DATA_DIR,\n",
    "    filters=training_filters,\n",
    "    transform=full_training_transforms,\n",
    "    level_from=\"rcmc\",\n",
    "    level_to=\"az\",\n",
    "    batch_size=32,                  # Larger batch for GPU efficiency\n",
    "    num_workers=4,                  # Parallel loading\n",
    "    patch_size=(1000, 1000),\n",
    "    stride=(500, 500),              # 50% overlap for more samples\n",
    "    buffer=(1000, 1000),\n",
    "    patch_order=\"chunk\",\n",
    "    shuffle_files=True,             # Randomize product order\n",
    "    complex_valued=True,\n",
    "    online=True,\n",
    "    max_products=None,              # Use all available products\n",
    "    samples_per_prod=1000,          # Dense sampling\n",
    "    cache_size=50,                  # Cache multiple products\n",
    "    verbose=False,                  # Quiet mode for training\n",
    "    use_balanced_sampling=True      # Geographic balance (requires sklearn)\n",
    ")\n",
    "print('âœ“ Full training loader ready\\n')\n",
    "\n",
    "# ============================================================================\n",
    "# ðŸ”¬ CONFIG 3: VERTICAL SLICE ANALYSIS (Range Direction)\n",
    "# ============================================================================\n",
    "print('='*80)\n",
    "print('ðŸ”¬ Configuration 3: Vertical Slice Analysis')\n",
    "print('='*80 + '\\n')\n",
    "\n",
    "loader_vertical = get_sar_dataloader(\n",
    "    data_dir=DATA_DIR,\n",
    "    level_from=\"rcmc\",\n",
    "    level_to=\"az\",\n",
    "    batch_size=16,\n",
    "    num_workers=0,\n",
    "    patch_mode=\"rectangular\",\n",
    "    patch_size=(1, -1),             # Full width, 1-pixel height (horizontal slices)\n",
    "    buffer=(1000, 0),               # Buffer only top/bottom\n",
    "    stride=(1, 1),                  # Sample every row\n",
    "    patch_order=\"row\",              # Row-by-row sampling\n",
    "    complex_valued=True,\n",
    "    online=True,\n",
    "    max_products=1,\n",
    "    samples_per_prod=100,\n",
    "    cache_size=1,\n",
    "    verbose=False\n",
    ")\n",
    "print('âœ“ Vertical slice loader ready')\n",
    "print('  Output shape: (batch, 2, 1, full_width) or (batch, 1, full_width) if complex\\n')\n",
    "\n",
    "# ============================================================================\n",
    "# ðŸ“Š CONFIG 4: HORIZONTAL SLICE ANALYSIS (Azimuth Direction)\n",
    "# ============================================================================\n",
    "print('='*80)\n",
    "print('ðŸ“Š Configuration 4: Horizontal Slice Analysis')\n",
    "print('='*80 + '\\n')\n",
    "\n",
    "loader_horizontal = get_sar_dataloader(\n",
    "    data_dir=DATA_DIR,\n",
    "    level_from=\"rcmc\",\n",
    "    level_to=\"az\",\n",
    "    batch_size=16,\n",
    "    num_workers=0,\n",
    "    patch_mode=\"rectangular\",\n",
    "    patch_size=(-1, 1),             # Full height, 1-pixel width (vertical slices)\n",
    "    buffer=(0, 1000),               # Buffer only left/right\n",
    "    stride=(1, 1),                  # Sample every column\n",
    "    patch_order=\"col\",              # Column-by-column sampling\n",
    "    complex_valued=True,\n",
    "    online=True,\n",
    "    max_products=1,\n",
    "    samples_per_prod=100,\n",
    "    cache_size=1,\n",
    "    verbose=False\n",
    ")\n",
    "print('âœ“ Horizontal slice loader ready')\n",
    "print('  Output shape: (batch, 2, full_height, 1) or (batch, full_height, 1) if complex\\n')\n",
    "\n",
    "# ============================================================================\n",
    "# ðŸŽ“ CONFIG 5: SEQUENCE LEARNING (With Positional Encoding)\n",
    "# ============================================================================\n",
    "print('='*80)\n",
    "print('ðŸŽ“ Configuration 5: Sequence Learning (Transformer-Ready)')\n",
    "print('='*80 + '\\n')\n",
    "\n",
    "loader_sequence = get_sar_dataloader(\n",
    "    data_dir=DATA_DIR,\n",
    "    level_from=\"rcmc\",\n",
    "    level_to=\"az\",\n",
    "    batch_size=8,\n",
    "    num_workers=0,\n",
    "    patch_size=(100, 1),            # Thin vertical patches\n",
    "    buffer=(1000, 1000),\n",
    "    stride=(100, 1),                # Non-overlapping\n",
    "    patch_order=\"col\",              # Column-wise for sequences\n",
    "    complex_valued=False,           # Real/imag as separate channels\n",
    "    positional_encoding=True,       # Add spatial coordinates\n",
    "    concatenate_patches=True,       # Stack patches into sequences\n",
    "    concat_axis=0,                  # Concatenate vertically\n",
    "    max_base_sample_size=(5000, 1000),  # Limit sequence length\n",
    "    online=True,\n",
    "    max_products=2,\n",
    "    samples_per_prod=100,\n",
    "    cache_size=2,\n",
    "    verbose=False\n",
    ")\n",
    "print('âœ“ Sequence learning loader ready')\n",
    "print('  Output shape: (batch, channels, sequence_length, feature_dim)')\n",
    "print('  Positional encoding adds 2 extra channels with (y, x) coordinates\\n')\n",
    "\n",
    "# ============================================================================\n",
    "# ðŸ§© CONFIG 6: BLOCK PATTERN SAMPLING (Stratified Coverage)\n",
    "# ============================================================================\n",
    "print('='*80)\n",
    "print('ðŸ§© Configuration 6: Block Pattern Sampling')\n",
    "print('='*80 + '\\n')\n",
    "\n",
    "loader_blocks = get_sar_dataloader(\n",
    "    data_dir=DATA_DIR,\n",
    "    level_from=\"rcmc\",\n",
    "    level_to=\"az\",\n",
    "    batch_size=16,\n",
    "    num_workers=0,\n",
    "    patch_size=(100, 100),\n",
    "    buffer=(1000, 1000),\n",
    "    stride=(100, 100),\n",
    "    block_pattern=(32, 32),         # Divide into 32Ã—32 grid of blocks\n",
    "    patch_order=\"row\",              # Within each block\n",
    "    complex_valued=True,\n",
    "    online=True,\n",
    "    max_products=1,\n",
    "    samples_per_prod=200,\n",
    "    cache_size=1,\n",
    "    verbose=False\n",
    ")\n",
    "print('âœ“ Block pattern loader ready')\n",
    "print('  Ensures stratified sampling across entire SAR product')\n",
    "print('  Good for capturing diverse spatial characteristics\\n')\n",
    "\n",
    "# ============================================================================\n",
    "# ðŸ”„ CONFIG 7: END-TO-END LEARNING (Raw â†’ Focused)\n",
    "# ============================================================================\n",
    "print('='*80)\n",
    "print('ðŸ”„ Configuration 7: End-to-End SAR Processing')\n",
    "print('='*80 + '\\n')\n",
    "\n",
    "e2e_transforms = SARTransform(\n",
    "    transform_raw=functools.partial(minmax_normalize, array_min=RC_MIN, array_max=RC_MAX),\n",
    "    transform_az=functools.partial(minmax_normalize, array_min=GT_MIN, array_max=GT_MAX)\n",
    ")\n",
    "\n",
    "loader_e2e = get_sar_dataloader(\n",
    "    data_dir=DATA_DIR,\n",
    "    level_from=\"raw\",               # Start from Level 0 raw data\n",
    "    level_to=\"az\",                  # End with Level 1 focused image\n",
    "    transform=e2e_transforms,\n",
    "    batch_size=8,\n",
    "    num_workers=0,\n",
    "    patch_size=(2000, 2000),        # Larger patches for full processing\n",
    "    buffer=(1000, 1000),\n",
    "    stride=(2000, 2000),\n",
    "    patch_order=\"chunk\",\n",
    "    complex_valued=True,\n",
    "    online=True,\n",
    "    max_products=2,\n",
    "    samples_per_prod=50,\n",
    "    cache_size=2,\n",
    "    verbose=False\n",
    ")\n",
    "print('âœ“ End-to-end loader ready')\n",
    "print('  Most challenging task: complete focusing pipeline')\n",
    "print('  Requires learning all intermediate processing steps\\n')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "maya4-3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

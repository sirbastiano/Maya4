{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92f44984",
   "metadata": {},
   "source": [
    "## üéØ Complete Maya4 Functionality Showcase\n",
    "\n",
    "This comprehensive example demonstrates all major features of the Maya4 SAR dataloader in a single, well-documented cell. \n",
    "\n",
    "**What you'll learn:**\n",
    "- Data source configuration (local/online)\n",
    "- Processing level selection (raw ‚Üí rc ‚Üí rcmc ‚Üí az)\n",
    "- Filtering by year, polarization, stripmap mode, and location\n",
    "- Patch extraction strategies and ordering\n",
    "- Normalization and transformations\n",
    "- Complex vs real-valued data handling\n",
    "- Positional encoding for spatial awareness\n",
    "- Advanced features: concatenation, block patterns, balanced sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae9658d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import functools\n",
    "import numpy as np\n",
    "\n",
    "# Import Maya4 core components\n",
    "from maya4 import (\n",
    "    get_sar_dataloader,      # Main dataloader factory function\n",
    "    SARTransform,             # Transformation pipeline for normalization\n",
    "    SampleFilter,             # Filter for selecting specific SAR products\n",
    "    minmax_normalize,         # Normalization utility function\n",
    "    RC_MIN, RC_MAX,          # Min/max values for Range Compressed data\n",
    "    GT_MIN, GT_MAX           # Min/max values for Ground Truth (Azimuth focused) data\n",
    ")\n",
    "\n",
    "# ============================================================================\n",
    "# üìÅ STEP 1: DATA DIRECTORY SETUP\n",
    "# ============================================================================\n",
    "# Define where SAR products are stored locally (or will be downloaded to)\n",
    "\n",
    "DATA_DIR = os.path.abspath(os.path.join(os.getcwd(), '..', 'data'))\n",
    "print(f'üìÇ Data directory: {DATA_DIR}')\n",
    "print(f'‚úì Directory exists: {os.path.exists(DATA_DIR)}\\n')\n",
    "\n",
    "# Create directory if it doesn't exist\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "\n",
    "# ============================================================================\n",
    "# üéõÔ∏è STEP 2: SAMPLE FILTERING (What data to load?)\n",
    "# ============================================================================\n",
    "# SampleFilter allows you to select specific SAR products based on metadata\n",
    "\n",
    "filters = SampleFilter(\n",
    "    # years: List of acquisition years to include (e.g., [2023, 2024])\n",
    "    # Only products from these years will be loaded\n",
    "    years=[2023, 2024],\n",
    "    \n",
    "    # polarizations: Radar polarization modes to include\n",
    "    # Options: \"hh\", \"hv\", \"vh\", \"vv\" (H=horizontal, V=vertical)\n",
    "    # \"hh\" = horizontal transmit, horizontal receive (co-pol)\n",
    "    # \"hv\" = horizontal transmit, vertical receive (cross-pol)\n",
    "    polarizations=[\"hh\"],\n",
    "    \n",
    "    # stripmap_modes: Sentinel-1 stripmap beam modes (1-6)\n",
    "    # Different modes have different swath widths and resolutions\n",
    "    # Modes 1-3: narrow swaths, higher resolution\n",
    "    # Modes 4-6: wider swaths, lower resolution\n",
    "    stripmap_modes=[1, 2, 3],\n",
    "    \n",
    "    # parts: Geographic regions/partitions in the dataset\n",
    "    # Maya4 organizes data into parts (PT1, PT2, etc.) by location\n",
    "    # Leave empty or None to include all parts\n",
    "    parts=[\"PT1\"]\n",
    ")\n",
    "\n",
    "# ============================================================================\n",
    "# üîÑ STEP 3: TRANSFORMATION PIPELINE (How to normalize data?)\n",
    "# ============================================================================\n",
    "# SARTransform defines how to normalize/transform data at each processing level\n",
    "# Each level can have its own transformation function\n",
    "\n",
    "transforms = SARTransform(\n",
    "    # transform_raw: Applied to Level 0 (raw) data\n",
    "    # Raw data typically has different statistics than compressed data\n",
    "    transform_raw=functools.partial(\n",
    "        minmax_normalize, \n",
    "        array_min=RC_MIN,  # Minimum value for normalization\n",
    "        array_max=RC_MAX   # Maximum value for normalization\n",
    "    ),\n",
    "    \n",
    "    # transform_rc: Applied to Range Compressed data\n",
    "    # RC is the first compression step (range direction only)\n",
    "    transform_rc=functools.partial(\n",
    "        minmax_normalize,\n",
    "        array_min=RC_MIN,\n",
    "        array_max=RC_MAX\n",
    "    ),\n",
    "    \n",
    "    # transform_rcmc: Applied to Range Cell Migration Corrected data\n",
    "    # RCMC corrects for range cell migration due to platform motion\n",
    "    transform_rcmc=functools.partial(\n",
    "        minmax_normalize,\n",
    "        array_min=RC_MIN,\n",
    "        array_max=RC_MAX\n",
    "    ),\n",
    "    \n",
    "    # transform_az: Applied to Azimuth focused (final) data\n",
    "    # This is the ground truth - fully focused SAR image\n",
    "    transform_az=functools.partial(\n",
    "        minmax_normalize,\n",
    "        array_min=GT_MIN,  # Different min/max for focused data\n",
    "        array_max=GT_MAX\n",
    "    )\n",
    ")\n",
    "\n",
    "# ============================================================================\n",
    "# üéØ STEP 4: CREATE THE DATALOADER (Main configuration)\n",
    "# ============================================================================\n",
    "print('='*80)\n",
    "print('üîß Creating Maya4 SAR Dataloader with comprehensive configuration...')\n",
    "print('='*80 + '\\n')\n",
    "\n",
    "loader = get_sar_dataloader(\n",
    "    # -------------------------------------------------------------------------\n",
    "    # üìÅ DATA SOURCE CONFIGURATION\n",
    "    # -------------------------------------------------------------------------\n",
    "    \n",
    "    # data_dir: Local directory for storing/loading SAR products\n",
    "    # Products are organized as: data_dir/[part]/[product_name].zarr/\n",
    "    data_dir=DATA_DIR,\n",
    "    \n",
    "    # online: Enable automatic downloading from HuggingFace Hub\n",
    "    # - True: Downloads missing products from Maya4 HF organization\n",
    "    # - False: Only uses locally available products\n",
    "    # Note: Requires HF authentication for private datasets\n",
    "    online=True,\n",
    "    \n",
    "    # filters: SampleFilter object to select specific products\n",
    "    # Apply metadata-based filtering (year, polarization, mode, location)\n",
    "    filters=filters,\n",
    "    \n",
    "    # max_products: Maximum number of SAR products to load\n",
    "    # Useful for testing or limiting dataset size\n",
    "    # Set to None to load all available products matching filters\n",
    "    max_products=5,\n",
    "    \n",
    "    # file_pattern: Regex pattern to match specific filenames (optional)\n",
    "    # Example: \".*20230508.*\" to load only products from May 8, 2023\n",
    "    # Leave as None to include all files matching other filters\n",
    "    file_pattern=None,\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # üéöÔ∏è PROCESSING LEVEL SELECTION\n",
    "    # -------------------------------------------------------------------------\n",
    "    \n",
    "    # level_from: Input processing level (what we learn from)\n",
    "    # Options: \"raw\" (L0), \"rc\", \"rcmc\", \"az\" (L1)\n",
    "    # This is the X in your training pair (input)\n",
    "    level_from=\"rcmc\",\n",
    "    \n",
    "    # level_to: Target processing level (what we predict)\n",
    "    # Options: \"raw\", \"rc\", \"rcmc\", \"az\"\n",
    "    # This is the Y in your training pair (target/label)\n",
    "    level_to=\"az\",\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # üß© PATCH EXTRACTION CONFIGURATION\n",
    "    # -------------------------------------------------------------------------\n",
    "    \n",
    "    # patch_mode: How to extract patches from the full SAR image\n",
    "    # - \"rectangular\": Extract rectangular patches (most common)\n",
    "    # - Other modes may be added in future versions\n",
    "    patch_mode=\"rectangular\",\n",
    "    \n",
    "    # patch_size: (height, width) of extracted patches in pixels\n",
    "    # - (H, W): Extract patches of fixed size H√óW\n",
    "    # - (H, -1): Full width, fixed height (entire rows)\n",
    "    # - (-1, W): Full height, fixed width (entire columns)\n",
    "    # - (-1, -1): Entire image (not recommended for large products)\n",
    "    # Example: (1, 1000) extracts 1√ó1000 horizontal slices\n",
    "    patch_size=(1000, 1000),\n",
    "    \n",
    "    # buffer: (vertical, horizontal) buffer zones at image boundaries\n",
    "    # Excludes this many pixels from edges to avoid boundary artifacts\n",
    "    # Example: (1000, 1000) excludes 1000 pixels from each edge\n",
    "    buffer=(500, 500),\n",
    "    \n",
    "    # stride: (vertical, horizontal) step size between patches\n",
    "    # - stride < patch_size: Overlapping patches\n",
    "    # - stride = patch_size: Non-overlapping patches (tiles)\n",
    "    # - stride > patch_size: Skip regions between patches\n",
    "    # Example: (1000, 1000) with patch_size (1000, 1000) = no overlap\n",
    "    stride=(1000, 1000),\n",
    "    \n",
    "    # max_base_sample_size: (height, width) maximum size for base samples\n",
    "    # When concatenate_patches=True, limits the size of concatenated blocks\n",
    "    # Helps manage memory usage when creating large composite samples\n",
    "    # Set to None for no limit\n",
    "    max_base_sample_size=None,\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # üìä PATCH ORDERING AND SAMPLING STRATEGY\n",
    "    # -------------------------------------------------------------------------\n",
    "    \n",
    "    # patch_order: Order in which patches are extracted and sampled\n",
    "    # - \"row\": Sample patches row-by-row (left to right, top to bottom)\n",
    "    # - \"col\": Sample patches column-by-column (top to bottom, left to right)\n",
    "    # - \"chunk\": Sample based on underlying Zarr chunk structure (I/O efficient)\n",
    "    # \"chunk\" is typically fastest as it respects data storage layout\n",
    "    patch_order=\"chunk\",\n",
    "    \n",
    "    # shuffle_files: Shuffle the order of SAR products\n",
    "    # - True: Random product order each epoch\n",
    "    # - False: Deterministic product order\n",
    "    shuffle_files=True,\n",
    "    \n",
    "    # use_balanced_sampling: Balance samples across geographic locations\n",
    "    # Uses K-means clustering on lat/lon to ensure geographic diversity\n",
    "    # Requires sklearn and at least ~10 products\n",
    "    # - True: Equal representation from different geographic areas\n",
    "    # - False: No geographic balancing\n",
    "    use_balanced_sampling=False,\n",
    "    \n",
    "    # block_pattern: (vertical_blocks, horizontal_blocks) for block sampling\n",
    "    # Divides each product into blocks and samples within blocks\n",
    "    # Example: (32, -1) creates 32 vertical blocks, full horizontal extent\n",
    "    # Set to None for standard patch extraction\n",
    "    block_pattern=None,\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # üî¢ DATA TYPE AND REPRESENTATION\n",
    "    # -------------------------------------------------------------------------\n",
    "    \n",
    "    # complex_valued: Return data as complex numbers or separate real/imag\n",
    "    # - True: Complex64 tensors (native SAR representation)\n",
    "    # - False: Float32 tensors with separate real and imaginary channels\n",
    "    #          Shape changes from (B, H, W) to (B, 2, H, W)\n",
    "    complex_valued=True,\n",
    "    \n",
    "    # positional_encoding: Add spatial position information to samples\n",
    "    # Appends normalized (row, col) coordinates as additional channels\n",
    "    # Useful for models that need spatial awareness\n",
    "    # - True: Adds 2 channels with position info\n",
    "    # - False: Only returns SAR data\n",
    "    positional_encoding=True,\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # üîó ADVANCED: PATCH CONCATENATION\n",
    "    # -------------------------------------------------------------------------\n",
    "    \n",
    "    # concatenate_patches: Stack multiple patches into larger samples\n",
    "    # Useful for creating longer sequences or larger spatial contexts\n",
    "    # - True: Concatenate patches along specified axis\n",
    "    # - False: Return individual patches\n",
    "    concatenate_patches=False,\n",
    "    \n",
    "    # concat_axis: Axis along which to concatenate patches\n",
    "    # Only used when concatenate_patches=True\n",
    "    # - 0: Vertical concatenation (stack patches vertically)\n",
    "    # - 1: Horizontal concatenation (stack patches horizontally)\n",
    "    concat_axis=0,\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # üîÑ TRANSFORMATION AND NORMALIZATION\n",
    "    # -------------------------------------------------------------------------\n",
    "    \n",
    "    # transform: SARTransform object defining normalization pipeline\n",
    "    # Applied to data at each processing level\n",
    "    # Set to None to disable normalization (use raw values)\n",
    "    transform=transforms,\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # üéõÔ∏è DATALOADER CONFIGURATION\n",
    "    # -------------------------------------------------------------------------\n",
    "    \n",
    "    # batch_size: Number of samples per batch\n",
    "    # Standard PyTorch DataLoader parameter\n",
    "    batch_size=8,\n",
    "    \n",
    "    # num_workers: Number of parallel workers for data loading\n",
    "    # - 0: Load data in main process (good for debugging)\n",
    "    # - >0: Use multiprocessing (faster but harder to debug)\n",
    "    # Recommended: 2-4 for most use cases\n",
    "    num_workers=0,\n",
    "    \n",
    "    # samples_per_prod: Number of patches to extract per SAR product\n",
    "    # Controls how many samples each product contributes per epoch\n",
    "    # Higher values = more thorough coverage but longer epochs\n",
    "    samples_per_prod=100,\n",
    "    \n",
    "    # cache_size: Number of products to keep in memory cache\n",
    "    # Larger cache = fewer disk reads but more memory usage\n",
    "    # Recommended: 10-100 depending on available RAM\n",
    "    cache_size=10,\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # üóÑÔ∏è STORAGE BACKEND\n",
    "    # -------------------------------------------------------------------------\n",
    "    \n",
    "    # backend: Storage format for SAR products\n",
    "    # - \"zarr\": Zarr format (default, supports cloud streaming)\n",
    "    # - Other backends may be added in future versions\n",
    "    backend=\"zarr\",\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # üêõ DEBUGGING AND DEVELOPMENT\n",
    "    # -------------------------------------------------------------------------\n",
    "    \n",
    "    # verbose: Print detailed information during initialization and loading\n",
    "    # - True: Show download progress, cache info, debugging messages\n",
    "    # - False: Minimal output\n",
    "    verbose=True,\n",
    "    \n",
    "    # save_samples: Save extracted patches to disk for inspection\n",
    "    # Useful for debugging and visualizing what the model sees\n",
    "    # - True: Save patches as image files\n",
    "    # - False: No saving (recommended for training)\n",
    "    save_samples=False\n",
    ")\n",
    "\n",
    "# ============================================================================\n",
    "# üèÉ STEP 5: ITERATE THROUGH BATCHES\n",
    "# ============================================================================\n",
    "print('\\n' + '='*80)\n",
    "print('üìä Loading batches and inspecting shapes...')\n",
    "print('='*80 + '\\n')\n",
    "\n",
    "# Counter for demonstration\n",
    "num_batches_to_show = 5\n",
    "\n",
    "for i, (x_batch, y_batch) in enumerate(loader):\n",
    "    # x_batch: Input data (level_from)\n",
    "    # y_batch: Target data (level_to)\n",
    "    \n",
    "    print(f'Batch {i:3d}: X shape: {str(x_batch.shape):20s} | Y shape: {str(y_batch.shape):20s}')\n",
    "    \n",
    "    # Show data statistics for first batch\n",
    "    if i == 0:\n",
    "        print(f'\\nüìà First batch statistics:')\n",
    "        print(f'   X - min: {x_batch.min():.4f}, max: {x_batch.max():.4f}, mean: {x_batch.mean():.4f}')\n",
    "        print(f'   Y - min: {y_batch.min():.4f}, max: {y_batch.max():.4f}, mean: {y_batch.mean():.4f}')\n",
    "        print(f'   X dtype: {x_batch.dtype}, Y dtype: {y_batch.dtype}\\n')\n",
    "    \n",
    "    # Stop after showing a few batches for demonstration\n",
    "    if i >= num_batches_to_show - 1:\n",
    "        break\n",
    "\n",
    "print('\\n' + '='*80)\n",
    "print('‚úÖ SUCCESS! Maya4 dataloader is working correctly.')\n",
    "print('='*80)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
